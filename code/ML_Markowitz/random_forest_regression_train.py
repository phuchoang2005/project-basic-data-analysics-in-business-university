import os
import pandas as pd
import numpy as np
import joblib

from sklearn.ensemble import RandomForestRegressor  # GPU
gpu_available = False

# ====== C·∫•u h√¨nh ======
INPUT_FILE = "train.csv"  # File ƒë·∫ßu v√†o
MODEL_DIR = "models"             # Th∆∞ m·ª•c l∆∞u m√¥ h√¨nh
os.makedirs(MODEL_DIR, exist_ok=True)

# ====== ƒê·ªçc d·ªØ li·ªáu ======
df = pd.read_csv(INPUT_FILE)
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values(by=['ticker', 'Date'])

# ====== X·ª≠ l√Ω theo t·ª´ng ticker ======
for ticker, data in df.groupby('ticker'):
    print(f"üîπ Training model for {ticker}...")

    data['return'] = data['adjclose'].pct_change()
    data.dropna(inplace=True)

    # T·∫°o ƒë·∫∑c tr∆∞ng (lags)
    for lag in range(1, 4):
        data[f'return_lag{lag}'] = data['return'].shift(lag)
    data.dropna(inplace=True)

    X = data[[f'return_lag{i}' for i in range(1, 4)]]
    y = data['return']

    if len(data) < 20:
        print(f"‚ö†Ô∏è Skipping {ticker} ‚Äî not enough data ({len(data)} rows)")
        continue

    # Hu·∫•n luy·ªán m√¥ h√¨nh
    model = RandomForestRegressor(
        n_estimators=200,
        max_depth=8,
        random_state=42,
    )
    model.fit(X, y)

    # L∆∞u m√¥ h√¨nh
    model_path = os.path.join(MODEL_DIR, f"{ticker}_model.pkl")
    joblib.dump(model, model_path)

    print(f"‚úÖ Saved model: {model_path}")

print("\nüéØ Training complete. All models saved to 'models/' directory.")
